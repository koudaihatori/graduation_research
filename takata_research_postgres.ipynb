{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./input/postgres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactionid</th>\n",
       "      <th>commitdate</th>\n",
       "      <th>ns</th>\n",
       "      <th>nm</th>\n",
       "      <th>nf</th>\n",
       "      <th>entropy</th>\n",
       "      <th>la</th>\n",
       "      <th>ld</th>\n",
       "      <th>lt</th>\n",
       "      <th>fix</th>\n",
       "      <th>ndev</th>\n",
       "      <th>pd</th>\n",
       "      <th>npt</th>\n",
       "      <th>exp</th>\n",
       "      <th>rexp</th>\n",
       "      <th>sexp</th>\n",
       "      <th>bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006/7/8 9:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.954434</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21140</td>\n",
       "      <td>8343.008333</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2006/5/28 22:53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2006/5/4 11:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2402</td>\n",
       "      <td>713.716667</td>\n",
       "      <td>2396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>2005/9/27 11:09</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>232.5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16307</td>\n",
       "      <td>5914.816667</td>\n",
       "      <td>15716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>2005/1/24 11:41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103234</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>804.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1778</td>\n",
       "      <td>712.283333</td>\n",
       "      <td>1774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transactionid       commitdate  ns  nm  nf   entropy        la        ld  \\\n",
       "0              1    2006/7/8 9:06   1   2   2  0.954434  0.102564  0.102564   \n",
       "1              6  2006/5/28 22:53   1   3   3  0.693298  0.333333  0.091503   \n",
       "2             10   2006/5/4 11:48   1   1   1  0.000000  0.097345  0.044248   \n",
       "3             28  2005/9/27 11:09   1   3   4  0.894836  0.035484  0.034409   \n",
       "4             41  2005/1/24 11:41   1   1   1  0.000000  0.103234  0.004975   \n",
       "\n",
       "      lt  fix  ndev  pd  npt    exp         rexp   sexp  bug  \n",
       "0   39.0    0     1  53  1.0  21140  8343.008333   1188    0  \n",
       "1  102.0    0     6  24  1.0     70    70.000000     70    0  \n",
       "2  113.0    1     3  41  1.0   2402   713.716667   2396    0  \n",
       "3  232.5    0     8  97  1.0  16307  5914.816667  15716    0  \n",
       "4  804.0    0     4   8  1.0   1778   712.283333   1774    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/numexpr/cpuinfo.py:76: UserWarning: [Errno 2] No such file or directory: 'sysctl'\n",
      "  stacklevel=stacklevel + 1):\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:21: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:22: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# ~expとn~を削除\n",
    "df[\"xexp\"]  = ((df[\"exp\"] + df[\"rexp\"] + df[\"sexp\"])/3)\n",
    "df[\"nx\"] = ((df[\"ns\"] + df[\"nm\"] )/2)\n",
    "df = df.ix[:,[0,1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15, 17, 18 ,16]]\n",
    "df\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "dropFeatures = [\"transactionid\",\"la\", \"exp\", \"rexp\", \"sexp\", \"commitdate\", \"ndev\", \"npt\", \"ns\", \"nm\"]\n",
    "X.drop(dropFeatures, axis =1, inplace=True)\n",
    "y = df.iloc[:, 18]\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:0.00636601448059082[sec]\n",
      "ロジスティック回帰の混合行列 [[881  38]\n",
      " [361  57]]\n",
      "ロジスティック回帰での正答率 0.7015706806282722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr = LogisticRegression()\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "y_p_lr = lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"ロジスティック回帰の混合行列\", confusion_matrix(y_test, y_p_lr))\n",
    "print (\"ロジスティック回帰での正答率\", accuracy_score(y_test, y_p_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:0.7415359020233154[sec]\n",
      "SVMでの正答率 0.6955871353777113\n",
      "ロジスティック回帰の混合行列 [[896  23]\n",
      " [384  34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "y_p_svm = svm.predict(X_test)\n",
    "# 正答率を算出\n",
    "print('SVMでの正答率', accuracy_score(y_test, y_p_svm))\n",
    "print(\"ロジスティック回帰の混合行列\", confusion_matrix(y_test, y_p_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:0.0015430450439453125[sec]\n",
      "knnの混合行列 [[845  74]\n",
      " [301 117]]\n",
      "knnでの正答率 0.7195213163799551\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEQCAYAAACqduMIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a383e9eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "list_nn = []\n",
    "list_score = []\n",
    "for k in range(1, 5):\n",
    "    knc = KNeighborsClassifier(n_neighbors=k)\n",
    "    knc.fit(X_train, y_train)\n",
    "    Y_pred = knc.predict(X_test)\n",
    "    score = knc.score(X_test, y_test)\n",
    "    list_nn.append(k)\n",
    "    list_score.append(score)\n",
    "\n",
    "#プロット\n",
    "plt.ylim(0.1, 1.0)\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.plot(list_nn, list_score)\n",
    "\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=2)\n",
    "start = time.time()\n",
    "knc.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "Y_pred = knc.predict(X_test)\n",
    "score = knc.score(X_test, y_test)\n",
    "print(\"knnの混合行列\", confusion_matrix(y_test, Y_pred))\n",
    "print (\"knnでの正答率\", accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv1D, UpSampling1D\n",
    "from keras.layers.pooling import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"relu\", input_dim=11, kernel_initializer=\"uniform\")`\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (11,) but got array with shape (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d61d89badd72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (11,) but got array with shape (8,)"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "import numpy as np\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def bug_model(activation=\"relu\", optimizer=\"adam\", out_dim=100):\n",
    "    dl_model = Sequential()\n",
    "    dl_model.add(Dense(out_dim, input_dim=8, init='uniform', activation=activation))\n",
    "    dl_model.add(Dense(out_dim, init='uniform', activation='relu'))\n",
    "    dl_model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    dl_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return dl_model\n",
    "    \n",
    "activation = [\"relu\", \"sigmoid\"]\n",
    "optimizer = [\"adam\", \"adagrad\"]\n",
    "out_dim = [100, 200]\n",
    "nb_epoch = [5, 10, 100]\n",
    "batch_size = [5, 10, 100]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dl_model.fit(X_train, y_train, nb_epoch=200, batch_size=10)\n",
    "dl_model = KerasClassifier(build_fn=bug_model, verbose=0)\n",
    "param_grid = dict(activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  out_dim=out_dim, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size)\n",
    "grid = GridSearchCV(estimator=dl_model, param_grid=param_grid)\n",
    "\n",
    "start = time.time()\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "print (grid_result.best_score_)\n",
    "print (grid_result.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scores = dl_model.evaluate(X_test, y_test)\n",
    "\n",
    "# print(\"DLでの正答率\",round(scores[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndarray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodaihatori/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (8, 1), padding=\"same\")`\n",
      "/Users/kodaihatori/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (5, 1), padding=\"same\")`\n",
      "/Users/kodaihatori/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 1), padding=\"same\")`\n",
      "/Users/kodaihatori/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "/Users/kodaihatori/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ipykernel_launcher.py:86: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3118 samples, validate on 1337 samples\n",
      "Epoch 1/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.6259 - acc: 0.6838 - val_loss: 0.6379 - val_acc: 0.6889\n",
      "Epoch 2/200\n",
      "3118/3118 [==============================] - 3s 958us/step - loss: 0.6119 - acc: 0.6969 - val_loss: 0.6501 - val_acc: 0.6866\n",
      "Epoch 3/200\n",
      "3118/3118 [==============================] - 3s 968us/step - loss: 0.6088 - acc: 0.6976 - val_loss: 0.6954 - val_acc: 0.5759\n",
      "Epoch 4/200\n",
      "3118/3118 [==============================] - 3s 949us/step - loss: 0.6075 - acc: 0.6966 - val_loss: 0.6227 - val_acc: 0.6881\n",
      "Epoch 5/200\n",
      "3118/3118 [==============================] - 3s 952us/step - loss: 0.6037 - acc: 0.7017 - val_loss: 0.6300 - val_acc: 0.6896\n",
      "Epoch 6/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.6073 - acc: 0.7011 - val_loss: 0.6231 - val_acc: 0.6896\n",
      "Epoch 7/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.6052 - acc: 0.7017 - val_loss: 0.6250 - val_acc: 0.6911\n",
      "Epoch 8/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.6016 - acc: 0.7056 - val_loss: 0.6326 - val_acc: 0.6956\n",
      "Epoch 9/200\n",
      "3118/3118 [==============================] - 3s 966us/step - loss: 0.6005 - acc: 0.7046 - val_loss: 0.6393 - val_acc: 0.6978\n",
      "Epoch 10/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5972 - acc: 0.7014 - val_loss: 0.6442 - val_acc: 0.6918\n",
      "Epoch 11/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.6012 - acc: 0.7030 - val_loss: 0.6071 - val_acc: 0.6971\n",
      "Epoch 12/200\n",
      "3118/3118 [==============================] - 5s 1ms/step - loss: 0.5971 - acc: 0.7065 - val_loss: 0.6127 - val_acc: 0.6993\n",
      "Epoch 13/200\n",
      "3118/3118 [==============================] - 5s 1ms/step - loss: 0.5934 - acc: 0.7027 - val_loss: 0.6230 - val_acc: 0.6933\n",
      "Epoch 14/200\n",
      "3118/3118 [==============================] - 5s 2ms/step - loss: 0.5988 - acc: 0.7033 - val_loss: 0.6269 - val_acc: 0.7001\n",
      "Epoch 15/200\n",
      "3118/3118 [==============================] - 5s 1ms/step - loss: 0.5950 - acc: 0.7040 - val_loss: 0.6135 - val_acc: 0.7016\n",
      "Epoch 16/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5925 - acc: 0.7097 - val_loss: 0.6346 - val_acc: 0.6956\n",
      "Epoch 17/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5950 - acc: 0.7037 - val_loss: 0.6033 - val_acc: 0.7001\n",
      "Epoch 18/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5895 - acc: 0.7126 - val_loss: 0.6144 - val_acc: 0.7038\n",
      "Epoch 19/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5943 - acc: 0.7110 - val_loss: 0.6019 - val_acc: 0.7001\n",
      "Epoch 20/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5917 - acc: 0.7043 - val_loss: 0.6227 - val_acc: 0.7046\n",
      "Epoch 21/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5895 - acc: 0.7120 - val_loss: 0.6527 - val_acc: 0.6904\n",
      "Epoch 22/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5895 - acc: 0.7152 - val_loss: 0.6235 - val_acc: 0.6926\n",
      "Epoch 23/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5927 - acc: 0.7062 - val_loss: 0.6154 - val_acc: 0.6971\n",
      "Epoch 24/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5884 - acc: 0.7123 - val_loss: 0.6332 - val_acc: 0.6672\n",
      "Epoch 25/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5887 - acc: 0.7104 - val_loss: 0.7540 - val_acc: 0.4862\n",
      "Epoch 26/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5906 - acc: 0.7107 - val_loss: 0.6105 - val_acc: 0.7053\n",
      "Epoch 27/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5872 - acc: 0.7091 - val_loss: 0.6525 - val_acc: 0.6335\n",
      "Epoch 28/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5885 - acc: 0.7097 - val_loss: 0.6345 - val_acc: 0.6986\n",
      "Epoch 29/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5861 - acc: 0.7146 - val_loss: 0.6398 - val_acc: 0.6993\n",
      "Epoch 30/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5882 - acc: 0.7081 - val_loss: 0.6099 - val_acc: 0.7023\n",
      "Epoch 31/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5849 - acc: 0.7094 - val_loss: 0.6030 - val_acc: 0.7053\n",
      "Epoch 32/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5857 - acc: 0.7149 - val_loss: 0.6799 - val_acc: 0.6118\n",
      "Epoch 33/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5834 - acc: 0.7146 - val_loss: 0.6383 - val_acc: 0.6986\n",
      "Epoch 34/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5839 - acc: 0.7126 - val_loss: 0.6101 - val_acc: 0.7053\n",
      "Epoch 35/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5841 - acc: 0.7085 - val_loss: 0.6752 - val_acc: 0.6971\n",
      "Epoch 36/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5827 - acc: 0.7110 - val_loss: 0.6004 - val_acc: 0.7016\n",
      "Epoch 37/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5796 - acc: 0.7139 - val_loss: 0.6515 - val_acc: 0.6425\n",
      "Epoch 38/200\n",
      "3118/3118 [==============================] - 3s 997us/step - loss: 0.5842 - acc: 0.7149 - val_loss: 0.5985 - val_acc: 0.7038\n",
      "Epoch 39/200\n",
      "3118/3118 [==============================] - 3s 987us/step - loss: 0.5850 - acc: 0.7117 - val_loss: 0.6232 - val_acc: 0.6986\n",
      "Epoch 40/200\n",
      "3118/3118 [==============================] - 3s 989us/step - loss: 0.5796 - acc: 0.7139 - val_loss: 0.6199 - val_acc: 0.7008\n",
      "Epoch 41/200\n",
      "3118/3118 [==============================] - 3s 997us/step - loss: 0.5810 - acc: 0.7136 - val_loss: 0.6402 - val_acc: 0.6963\n",
      "Epoch 42/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5810 - acc: 0.7158 - val_loss: 0.6219 - val_acc: 0.6911\n",
      "Epoch 43/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5837 - acc: 0.7162 - val_loss: 0.6345 - val_acc: 0.6963\n",
      "Epoch 44/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5819 - acc: 0.7136 - val_loss: 0.6104 - val_acc: 0.7046\n",
      "Epoch 45/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5821 - acc: 0.7123 - val_loss: 0.6087 - val_acc: 0.7038\n",
      "Epoch 46/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5797 - acc: 0.7178 - val_loss: 0.6172 - val_acc: 0.6978\n",
      "Epoch 47/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5810 - acc: 0.7130 - val_loss: 0.6223 - val_acc: 0.6911\n",
      "Epoch 48/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5840 - acc: 0.7165 - val_loss: 0.5997 - val_acc: 0.7038\n",
      "Epoch 49/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5796 - acc: 0.7174 - val_loss: 0.6163 - val_acc: 0.7016\n",
      "Epoch 50/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5809 - acc: 0.7158 - val_loss: 0.6237 - val_acc: 0.7008\n",
      "Epoch 51/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5806 - acc: 0.7152 - val_loss: 0.6400 - val_acc: 0.7001\n",
      "Epoch 52/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5805 - acc: 0.7162 - val_loss: 0.5989 - val_acc: 0.7091\n",
      "Epoch 53/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5807 - acc: 0.7120 - val_loss: 0.6019 - val_acc: 0.7083\n",
      "Epoch 54/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5797 - acc: 0.7165 - val_loss: 0.6013 - val_acc: 0.7053\n",
      "Epoch 55/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5790 - acc: 0.7191 - val_loss: 0.6536 - val_acc: 0.6545\n",
      "Epoch 56/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5763 - acc: 0.7229 - val_loss: 0.6241 - val_acc: 0.6836\n",
      "Epoch 57/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5786 - acc: 0.7162 - val_loss: 0.6071 - val_acc: 0.6956\n",
      "Epoch 58/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5765 - acc: 0.7184 - val_loss: 0.6077 - val_acc: 0.7068\n",
      "Epoch 59/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5823 - acc: 0.7200 - val_loss: 0.6039 - val_acc: 0.7053\n",
      "Epoch 60/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5778 - acc: 0.7210 - val_loss: 0.6874 - val_acc: 0.7008\n",
      "Epoch 61/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5775 - acc: 0.7235 - val_loss: 0.6049 - val_acc: 0.7091\n",
      "Epoch 62/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5774 - acc: 0.7207 - val_loss: 0.6158 - val_acc: 0.7016\n",
      "Epoch 63/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5792 - acc: 0.7171 - val_loss: 0.5999 - val_acc: 0.7023\n",
      "Epoch 64/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5776 - acc: 0.7149 - val_loss: 0.5970 - val_acc: 0.7046\n",
      "Epoch 65/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5753 - acc: 0.7229 - val_loss: 0.6237 - val_acc: 0.6814\n",
      "Epoch 66/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5767 - acc: 0.7149 - val_loss: 0.6049 - val_acc: 0.7001\n",
      "Epoch 67/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5755 - acc: 0.7152 - val_loss: 0.6062 - val_acc: 0.7105\n",
      "Epoch 68/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5777 - acc: 0.7174 - val_loss: 0.5967 - val_acc: 0.7046\n",
      "Epoch 69/200\n",
      "3118/3118 [==============================] - 3s 996us/step - loss: 0.5792 - acc: 0.7139 - val_loss: 0.6034 - val_acc: 0.7098\n",
      "Epoch 70/200\n",
      "3118/3118 [==============================] - 3s 997us/step - loss: 0.5757 - acc: 0.7194 - val_loss: 0.5959 - val_acc: 0.7098\n",
      "Epoch 71/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5768 - acc: 0.7133 - val_loss: 0.6000 - val_acc: 0.7076\n",
      "Epoch 72/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5737 - acc: 0.7197 - val_loss: 0.6272 - val_acc: 0.6694\n",
      "Epoch 73/200\n",
      "3118/3118 [==============================] - 3s 997us/step - loss: 0.5755 - acc: 0.7152 - val_loss: 0.5998 - val_acc: 0.7053\n",
      "Epoch 74/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5714 - acc: 0.7210 - val_loss: 0.6076 - val_acc: 0.7128\n",
      "Epoch 75/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5775 - acc: 0.7216 - val_loss: 0.5977 - val_acc: 0.7046\n",
      "Epoch 76/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5745 - acc: 0.7207 - val_loss: 0.5983 - val_acc: 0.7083\n",
      "Epoch 77/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5767 - acc: 0.7178 - val_loss: 0.5944 - val_acc: 0.7120\n",
      "Epoch 78/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5732 - acc: 0.7210 - val_loss: 0.5943 - val_acc: 0.7068\n",
      "Epoch 79/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5734 - acc: 0.7219 - val_loss: 0.6252 - val_acc: 0.6784\n",
      "Epoch 80/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5702 - acc: 0.7232 - val_loss: 0.6015 - val_acc: 0.7083\n",
      "Epoch 81/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5758 - acc: 0.7242 - val_loss: 0.6178 - val_acc: 0.6821\n",
      "Epoch 82/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5745 - acc: 0.7178 - val_loss: 0.5948 - val_acc: 0.7068\n",
      "Epoch 83/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5747 - acc: 0.7226 - val_loss: 0.6046 - val_acc: 0.7031\n",
      "Epoch 84/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5729 - acc: 0.7216 - val_loss: 0.6026 - val_acc: 0.7083\n",
      "Epoch 85/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5711 - acc: 0.7200 - val_loss: 0.6230 - val_acc: 0.7031\n",
      "Epoch 86/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5722 - acc: 0.7255 - val_loss: 0.6014 - val_acc: 0.7076\n",
      "Epoch 87/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5708 - acc: 0.7184 - val_loss: 0.6117 - val_acc: 0.6829\n",
      "Epoch 88/200\n",
      "3118/3118 [==============================] - 3s 961us/step - loss: 0.5720 - acc: 0.7171 - val_loss: 0.6076 - val_acc: 0.7038\n",
      "Epoch 89/200\n",
      "3118/3118 [==============================] - 3s 955us/step - loss: 0.5733 - acc: 0.7235 - val_loss: 0.6102 - val_acc: 0.7031\n",
      "Epoch 90/200\n",
      "3118/3118 [==============================] - 3s 964us/step - loss: 0.5730 - acc: 0.7200 - val_loss: 0.5966 - val_acc: 0.7091\n",
      "Epoch 91/200\n",
      "3118/3118 [==============================] - 3s 963us/step - loss: 0.5720 - acc: 0.7194 - val_loss: 0.5930 - val_acc: 0.7128\n",
      "Epoch 92/200\n",
      "3118/3118 [==============================] - 3s 972us/step - loss: 0.5731 - acc: 0.7203 - val_loss: 0.5964 - val_acc: 0.7076\n",
      "Epoch 93/200\n",
      "3118/3118 [==============================] - 3s 968us/step - loss: 0.5710 - acc: 0.7197 - val_loss: 0.6086 - val_acc: 0.7016\n",
      "Epoch 94/200\n",
      "3118/3118 [==============================] - 3s 968us/step - loss: 0.5708 - acc: 0.7232 - val_loss: 0.5988 - val_acc: 0.7091\n",
      "Epoch 95/200\n",
      "3118/3118 [==============================] - 3s 974us/step - loss: 0.5718 - acc: 0.7264 - val_loss: 0.6666 - val_acc: 0.7001\n",
      "Epoch 96/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5737 - acc: 0.7213 - val_loss: 0.6076 - val_acc: 0.7053\n",
      "Epoch 97/200\n",
      "3118/3118 [==============================] - 3s 983us/step - loss: 0.5719 - acc: 0.7197 - val_loss: 0.6485 - val_acc: 0.6978\n",
      "Epoch 98/200\n",
      "3118/3118 [==============================] - 3s 966us/step - loss: 0.5690 - acc: 0.7216 - val_loss: 0.6236 - val_acc: 0.6859\n",
      "Epoch 99/200\n",
      "3118/3118 [==============================] - 3s 960us/step - loss: 0.5706 - acc: 0.7280 - val_loss: 0.6075 - val_acc: 0.7135\n",
      "Epoch 100/200\n",
      "3118/3118 [==============================] - 3s 963us/step - loss: 0.5687 - acc: 0.7258 - val_loss: 0.5965 - val_acc: 0.7120\n",
      "Epoch 101/200\n",
      "3118/3118 [==============================] - 3s 972us/step - loss: 0.5683 - acc: 0.7219 - val_loss: 0.6123 - val_acc: 0.6918\n",
      "Epoch 102/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5692 - acc: 0.7248 - val_loss: 0.6001 - val_acc: 0.7105\n",
      "Epoch 103/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5666 - acc: 0.7248 - val_loss: 0.5988 - val_acc: 0.7120\n",
      "Epoch 104/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5702 - acc: 0.7245 - val_loss: 0.6067 - val_acc: 0.7031\n",
      "Epoch 105/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5710 - acc: 0.7213 - val_loss: 0.6388 - val_acc: 0.6664\n",
      "Epoch 106/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5700 - acc: 0.7171 - val_loss: 0.5965 - val_acc: 0.7135\n",
      "Epoch 107/200\n",
      "3118/3118 [==============================] - 3s 990us/step - loss: 0.5652 - acc: 0.7229 - val_loss: 0.6106 - val_acc: 0.6814\n",
      "Epoch 108/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5696 - acc: 0.7251 - val_loss: 0.6373 - val_acc: 0.6530\n",
      "Epoch 109/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5669 - acc: 0.7277 - val_loss: 0.6026 - val_acc: 0.7098\n",
      "Epoch 110/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5665 - acc: 0.7216 - val_loss: 0.6227 - val_acc: 0.7038\n",
      "Epoch 111/200\n",
      "3118/3118 [==============================] - 3s 976us/step - loss: 0.5676 - acc: 0.7261 - val_loss: 0.6040 - val_acc: 0.7076\n",
      "Epoch 112/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5650 - acc: 0.7306 - val_loss: 0.6078 - val_acc: 0.7031\n",
      "Epoch 113/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5689 - acc: 0.7248 - val_loss: 0.6393 - val_acc: 0.6597\n",
      "Epoch 114/200\n",
      "3118/3118 [==============================] - 5s 2ms/step - loss: 0.5664 - acc: 0.7261 - val_loss: 0.6027 - val_acc: 0.7105\n",
      "Epoch 115/200\n",
      "3118/3118 [==============================] - 5s 2ms/step - loss: 0.5633 - acc: 0.7284 - val_loss: 0.5970 - val_acc: 0.7128\n",
      "Epoch 116/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5669 - acc: 0.7232 - val_loss: 0.6081 - val_acc: 0.7023\n",
      "Epoch 117/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5685 - acc: 0.7210 - val_loss: 0.6006 - val_acc: 0.7113\n",
      "Epoch 118/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5649 - acc: 0.7303 - val_loss: 0.6109 - val_acc: 0.7076\n",
      "Epoch 119/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5671 - acc: 0.7290 - val_loss: 0.6165 - val_acc: 0.7038\n",
      "Epoch 120/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5689 - acc: 0.7226 - val_loss: 0.6456 - val_acc: 0.7031\n",
      "Epoch 121/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5675 - acc: 0.7248 - val_loss: 0.6313 - val_acc: 0.6776\n",
      "Epoch 122/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5651 - acc: 0.7271 - val_loss: 0.6023 - val_acc: 0.7068\n",
      "Epoch 123/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5627 - acc: 0.7245 - val_loss: 0.5941 - val_acc: 0.7053\n",
      "Epoch 124/200\n",
      "3118/3118 [==============================] - 3s 992us/step - loss: 0.5630 - acc: 0.7271 - val_loss: 0.6254 - val_acc: 0.6776\n",
      "Epoch 125/200\n",
      "3118/3118 [==============================] - 3s 994us/step - loss: 0.5620 - acc: 0.7261 - val_loss: 0.6036 - val_acc: 0.7128\n",
      "Epoch 126/200\n",
      "3118/3118 [==============================] - 3s 994us/step - loss: 0.5623 - acc: 0.7271 - val_loss: 0.5960 - val_acc: 0.7098\n",
      "Epoch 127/200\n",
      "3118/3118 [==============================] - 3s 998us/step - loss: 0.5618 - acc: 0.7261 - val_loss: 0.7094 - val_acc: 0.5714\n",
      "Epoch 128/200\n",
      "3118/3118 [==============================] - 3s 995us/step - loss: 0.5587 - acc: 0.7290 - val_loss: 0.5927 - val_acc: 0.7120\n",
      "Epoch 129/200\n",
      "3118/3118 [==============================] - 3s 995us/step - loss: 0.5636 - acc: 0.7290 - val_loss: 0.6727 - val_acc: 0.6148\n",
      "Epoch 130/200\n",
      "3118/3118 [==============================] - 3s 995us/step - loss: 0.5601 - acc: 0.7341 - val_loss: 0.5980 - val_acc: 0.7120\n",
      "Epoch 131/200\n",
      "3118/3118 [==============================] - 3s 995us/step - loss: 0.5595 - acc: 0.7303 - val_loss: 0.5966 - val_acc: 0.7120\n",
      "Epoch 132/200\n",
      "3118/3118 [==============================] - 3s 979us/step - loss: 0.5605 - acc: 0.7258 - val_loss: 0.6656 - val_acc: 0.6111\n",
      "Epoch 133/200\n",
      "3118/3118 [==============================] - 3s 964us/step - loss: 0.5591 - acc: 0.7284 - val_loss: 0.6049 - val_acc: 0.7113\n",
      "Epoch 134/200\n",
      "3118/3118 [==============================] - 3s 987us/step - loss: 0.5601 - acc: 0.7284 - val_loss: 0.5998 - val_acc: 0.7068\n",
      "Epoch 135/200\n",
      "3118/3118 [==============================] - 3s 996us/step - loss: 0.5614 - acc: 0.7239 - val_loss: 0.6188 - val_acc: 0.7091\n",
      "Epoch 136/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5592 - acc: 0.7306 - val_loss: 0.6546 - val_acc: 0.6358\n",
      "Epoch 137/200\n",
      "3118/3118 [==============================] - 5s 2ms/step - loss: 0.5599 - acc: 0.7328 - val_loss: 0.6066 - val_acc: 0.7091\n",
      "Epoch 138/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5620 - acc: 0.7274 - val_loss: 0.6148 - val_acc: 0.7068\n",
      "Epoch 139/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5660 - acc: 0.7290 - val_loss: 0.6262 - val_acc: 0.6761\n",
      "Epoch 140/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5586 - acc: 0.7351 - val_loss: 0.6192 - val_acc: 0.6926\n",
      "Epoch 141/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5583 - acc: 0.7309 - val_loss: 0.5991 - val_acc: 0.7120\n",
      "Epoch 142/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5612 - acc: 0.7306 - val_loss: 0.6180 - val_acc: 0.6956\n",
      "Epoch 143/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5621 - acc: 0.7280 - val_loss: 0.6816 - val_acc: 0.5969\n",
      "Epoch 144/200\n",
      "3118/3118 [==============================] - 3s 987us/step - loss: 0.5556 - acc: 0.7338 - val_loss: 0.5956 - val_acc: 0.7098\n",
      "Epoch 145/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5585 - acc: 0.7309 - val_loss: 0.7124 - val_acc: 0.5677\n",
      "Epoch 146/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5566 - acc: 0.7316 - val_loss: 0.6201 - val_acc: 0.7053\n",
      "Epoch 147/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5571 - acc: 0.7316 - val_loss: 0.5917 - val_acc: 0.7091\n",
      "Epoch 148/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5522 - acc: 0.7290 - val_loss: 0.7908 - val_acc: 0.4652\n",
      "Epoch 149/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5555 - acc: 0.7335 - val_loss: 0.6542 - val_acc: 0.7001\n",
      "Epoch 150/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5558 - acc: 0.7303 - val_loss: 0.6402 - val_acc: 0.6567\n",
      "Epoch 151/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5541 - acc: 0.7290 - val_loss: 0.6292 - val_acc: 0.6791\n",
      "Epoch 152/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5529 - acc: 0.7328 - val_loss: 0.5934 - val_acc: 0.7143\n",
      "Epoch 153/200\n",
      "3118/3118 [==============================] - 3s 996us/step - loss: 0.5532 - acc: 0.7316 - val_loss: 0.5948 - val_acc: 0.7113\n",
      "Epoch 154/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5517 - acc: 0.7348 - val_loss: 0.6392 - val_acc: 0.6567\n",
      "Epoch 155/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5506 - acc: 0.7341 - val_loss: 0.6581 - val_acc: 0.7031\n",
      "Epoch 156/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5566 - acc: 0.7284 - val_loss: 0.6183 - val_acc: 0.6904\n",
      "Epoch 157/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5515 - acc: 0.7389 - val_loss: 0.6394 - val_acc: 0.7008\n",
      "Epoch 158/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5530 - acc: 0.7341 - val_loss: 0.6975 - val_acc: 0.5879\n",
      "Epoch 159/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5530 - acc: 0.7351 - val_loss: 0.5976 - val_acc: 0.6978\n",
      "Epoch 160/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5548 - acc: 0.7325 - val_loss: 0.6914 - val_acc: 0.5924\n",
      "Epoch 161/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5480 - acc: 0.7348 - val_loss: 0.6421 - val_acc: 0.7053\n",
      "Epoch 162/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5500 - acc: 0.7354 - val_loss: 0.5979 - val_acc: 0.7105\n",
      "Epoch 163/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5533 - acc: 0.7309 - val_loss: 0.6480 - val_acc: 0.7046\n",
      "Epoch 164/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5500 - acc: 0.7332 - val_loss: 0.5999 - val_acc: 0.7135\n",
      "Epoch 165/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5504 - acc: 0.7316 - val_loss: 0.5957 - val_acc: 0.7180\n",
      "Epoch 166/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5490 - acc: 0.7402 - val_loss: 0.6205 - val_acc: 0.6971\n",
      "Epoch 167/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5557 - acc: 0.7322 - val_loss: 0.6100 - val_acc: 0.7046\n",
      "Epoch 168/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5480 - acc: 0.7380 - val_loss: 0.6471 - val_acc: 0.6642\n",
      "Epoch 169/200\n",
      "3118/3118 [==============================] - 3s 991us/step - loss: 0.5469 - acc: 0.7415 - val_loss: 0.5949 - val_acc: 0.7083\n",
      "Epoch 170/200\n",
      "3118/3118 [==============================] - 3s 984us/step - loss: 0.5472 - acc: 0.7344 - val_loss: 0.6896 - val_acc: 0.6028\n",
      "Epoch 171/200\n",
      "3118/3118 [==============================] - 3s 984us/step - loss: 0.5454 - acc: 0.7300 - val_loss: 0.6127 - val_acc: 0.7046\n",
      "Epoch 172/200\n",
      "3118/3118 [==============================] - 3s 994us/step - loss: 0.5513 - acc: 0.7354 - val_loss: 0.6612 - val_acc: 0.6387\n",
      "Epoch 173/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5479 - acc: 0.7328 - val_loss: 0.6288 - val_acc: 0.6911\n",
      "Epoch 174/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5468 - acc: 0.7393 - val_loss: 0.6325 - val_acc: 0.6724\n",
      "Epoch 175/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5457 - acc: 0.7364 - val_loss: 0.6379 - val_acc: 0.6926\n",
      "Epoch 176/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5489 - acc: 0.7393 - val_loss: 0.5990 - val_acc: 0.7076\n",
      "Epoch 177/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5456 - acc: 0.7354 - val_loss: 0.5984 - val_acc: 0.7068\n",
      "Epoch 178/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5435 - acc: 0.7399 - val_loss: 0.5957 - val_acc: 0.7031\n",
      "Epoch 179/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5445 - acc: 0.7348 - val_loss: 0.5951 - val_acc: 0.7135\n",
      "Epoch 180/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5437 - acc: 0.7396 - val_loss: 0.6191 - val_acc: 0.6896\n",
      "Epoch 181/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5439 - acc: 0.7296 - val_loss: 0.6743 - val_acc: 0.7053\n",
      "Epoch 182/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5456 - acc: 0.7335 - val_loss: 0.7659 - val_acc: 0.7001\n",
      "Epoch 183/200\n",
      "3118/3118 [==============================] - 5s 2ms/step - loss: 0.5420 - acc: 0.7351 - val_loss: 0.6044 - val_acc: 0.7023\n",
      "Epoch 184/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5435 - acc: 0.7360 - val_loss: 0.5955 - val_acc: 0.7023\n",
      "Epoch 185/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5421 - acc: 0.7351 - val_loss: 0.7139 - val_acc: 0.5894\n",
      "Epoch 186/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5435 - acc: 0.7421 - val_loss: 0.6399 - val_acc: 0.6821\n",
      "Epoch 187/200\n",
      "3118/3118 [==============================] - 3s 991us/step - loss: 0.5445 - acc: 0.7338 - val_loss: 0.6330 - val_acc: 0.7023\n",
      "Epoch 188/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5411 - acc: 0.7396 - val_loss: 0.6230 - val_acc: 0.7023\n",
      "Epoch 189/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5468 - acc: 0.7402 - val_loss: 0.6056 - val_acc: 0.6978\n",
      "Epoch 190/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5410 - acc: 0.7360 - val_loss: 0.5945 - val_acc: 0.7091\n",
      "Epoch 191/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5376 - acc: 0.7354 - val_loss: 0.7889 - val_acc: 0.4862\n",
      "Epoch 192/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5381 - acc: 0.7373 - val_loss: 0.6004 - val_acc: 0.7031\n",
      "Epoch 193/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5398 - acc: 0.7367 - val_loss: 0.6286 - val_acc: 0.6874\n",
      "Epoch 194/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5385 - acc: 0.7399 - val_loss: 0.6016 - val_acc: 0.7203\n",
      "Epoch 195/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5397 - acc: 0.7386 - val_loss: 0.6030 - val_acc: 0.7105\n",
      "Epoch 196/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5420 - acc: 0.7357 - val_loss: 0.6398 - val_acc: 0.7068\n",
      "Epoch 197/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5419 - acc: 0.7386 - val_loss: 0.7044 - val_acc: 0.5946\n",
      "Epoch 198/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5386 - acc: 0.7431 - val_loss: 0.6064 - val_acc: 0.7076\n",
      "Epoch 199/200\n",
      "3118/3118 [==============================] - 4s 1ms/step - loss: 0.5409 - acc: 0.7421 - val_loss: 0.6049 - val_acc: 0.7150\n",
      "Epoch 200/200\n",
      "3118/3118 [==============================] - 3s 1ms/step - loss: 0.5395 - acc: 0.7409 - val_loss: 0.7441 - val_acc: 0.5557\n",
      "0.5375734020151184 0.486163051619223\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "from __future__ import print_function\n",
    " \n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "import keras \n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "      \n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter = ',')\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "  \n",
    "nb_epochs = 200\n",
    "nb_classes = len(np.unique(y_test))\n",
    "batch_size = min(X_train.shape[0]/10, 16)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "\n",
    "print(X_train.__class__.__name__)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "X_train = (X_train - X_train_mean)/(X_train_std)\n",
    "\n",
    "X_test = (X_test - X_train_mean)/(X_train_std)\n",
    "X_train = X_train.reshape(X_train.shape + (1,1,))\n",
    "X_test = X_test.reshape(X_test.shape + (1,1,))\n",
    "\n",
    "x = keras.layers.Input(X_train.shape[1:])\n",
    "#    drop_out = Dropout(0.2)(x)\n",
    "conv1 = keras.layers.Conv2D(128, 8, 1, border_mode='same')(x)\n",
    "conv1 = keras.layers.normalization.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation('relu')(conv1)\n",
    "\n",
    "#    drop_out = Dropout(0.2)(conv1)\n",
    "conv2 = keras.layers.Conv2D(256, 5, 1, border_mode='same')(conv1)\n",
    "conv2 = keras.layers.normalization.BatchNormalization()(conv2)\n",
    "conv2 = keras.layers.Activation('relu')(conv2)\n",
    "\n",
    "#    drop_out = Dropout(0.2)(conv2)\n",
    "conv3 = keras.layers.Conv2D(128, 3, 1, border_mode='same')(conv2)\n",
    "conv3 = keras.layers.normalization.BatchNormalization()(conv3)\n",
    "conv3 = keras.layers.Activation('relu')(conv3)\n",
    "\n",
    "full = keras.layers.pooling.GlobalAveragePooling2D()(conv3)    \n",
    "out = keras.layers.Dense(nb_classes, activation='softmax')(full)\n",
    "\n",
    "\n",
    "model = Model(input=x, output=out)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'loss', factor=0.5,\n",
    "                  patience=50, min_lr=0.0001) \n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n",
    "          verbose=1, validation_data=(X_test, Y_test), callbacks = [reduce_lr])\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "#Print the testing results which has the lowest training loss.\n",
    "log = pd.DataFrame(hist.history)\n",
    "print(log.loc[log['loss'].idxmin]['loss'], log.loc[log['loss'].idxmin]['val_acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_6_input to have shape (13,) but got array with shape (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-49c5af0bc680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# モデル訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"elapsed_time:{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"[sec]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hatorikoudai/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_6_input to have shape (13,) but got array with shape (8,)"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def build_multilayer_perceptron():\n",
    "#     \"\"\"多層パーセプトロンモデルを構築\"\"\"\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Dense(16, input_shape=(13, )))\n",
    "    rnn_model.add(Activation('relu'))\n",
    "    rnn_model.add(Dense(2))\n",
    "    rnn_model.add(Activation('softmax'))\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# モデル構築\n",
    "rnn_model = build_multilayer_perceptron()\n",
    "rnn_model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# モデル訓練\n",
    "start = time.time()\n",
    "rnn_model.fit(X_train, y_train, nb_epoch=200, batch_size=3, verbose=1)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "# モデル評価\n",
    "loss, accuracy = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Accuracy = {:.3f}\".format(accuracy))\n",
    "\n",
    "print (\"RNNでの正答率\", round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
